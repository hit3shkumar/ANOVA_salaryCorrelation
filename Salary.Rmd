---
title: "Annual Salary Report"
author: "Hitesh Kumar Pounraj"
output:
  pdf_document: default
  html_document: default
---

```{r, echo=FALSE, results='hold'}
library(readr)
SalaryData <- read.csv("C:\\Users\\hites\\Documents\\School\\PastQtrs\\Git\\Salary.csv")
```

## Introduction
```{r, echo = FALSE}
cat("Is there statistical evidence to suggest there is an interaction effect between Profession and city of residence on salary. If not, are there Factor A or B effects (Profession and City)? We are interested in the answer to see whether what profession you practice and where you work affects your sallary in dollars. We will be taking the Two factor ANOVA Hypothesis test approach. For all the tests, we will be using the general F test.
")



```

## Summary
**(Histogram)**
```{r, echo = FALSE}

summary(SalaryData)

ntSD = nrow(SalaryData)
aSD = length(unique(SalaryData[,2]))
bSD = length(unique(SalaryData[,3]))
cat("nT:", ntSD,", a =",aSD, ", b =",bSD)

library(ggplot2)
ggplot(SalaryData, aes(x = Annual)) + geom_histogram(binwidth = 2,,color = "black",fill = "white") + facet_grid(Prof ~.) +ggtitle("Annual salary by profession")

ggplot(SalaryData, aes(x = Annual)) + geom_histogram(binwidth = 2,,color = "black",fill = "grey") + facet_grid(Region ~.) +ggtitle("Annual salary by region")
cat("The annual salary in thousands of dollars for 'Data Scientist', 'Software Engineer', 'Bioinformatics Engineer' in Seattle and San Francisco.")

interaction.plot(SalaryData$Prof, SalaryData$Region, SalaryData$Annual)
cat("By the plot, it seems to exist an interaction between Profession and Region")

```
**(BoxPlot)**
```{r, echo = FALSE}
cat('\n')
boxplot(Annual~Prof, data = SalaryData, horizontal = TRUE, xlab = "Change in salary based on profession", ylab = "Profession", main = "Profession ~ Annual Salary 'Box Plot'")
cat("The average salary is comparetively the highest in the Data Scientist profession according to the histogram")
aggregate(Annual~Prof, SalaryData,sd)

boxplot(Annual~Region, data = SalaryData, horizontal = TRUE, xlab = "Change in salary based on region", ylab = "Region", main = "Region ~ Annual Salary 'Box Plot'")
cat("The average weight loss is comparetively the highest in San Francisco according to the histogram")
aggregate(Annual~Region, SalaryData,sd)

```
**(Means)**
```{r, echo = FALSE}

find.means = function(the.data,fun.name = mean){
  a = length(unique(the.data[,2]))
  b = length(unique(the.data[,3]))
  means.A = by(the.data[,1], the.data[,2], fun.name)
  means.B = by(the.data[,1],the.data[,3],fun.name)
  means.AB = by(the.data[,1],list(the.data[,2],the.data[,3]),fun.name)
  MAB = matrix(means.AB,nrow = b, ncol = a, byrow = TRUE)
  colnames(MAB) = names(means.A)
  rownames(MAB) = names(means.B)
  MA = as.numeric(means.A)
  names(MA) = names(means.A)
  MB = as.numeric(means.B)
  names(MB) = names(means.B)
  results = list(A = MA, B = MB, AB = MAB)
  return(results)
}

salary.means =find.means(SalaryData,mean)
salaryData.means <- salary.means$AB
cat("Yij : ", '\n')
salaryData.means


```

##Diagnostic
```{r, echo = FALSE}

cat("We would like to find out if any form of this data will meet the assumption that all test statitics and CI's rely on:
    1: All subjects are randomly sampled
    2: All levels of Factor A are independent
    3: All levels of Factor B are independent
    4: eijk ~ N(0 , sd = sigma-e) ", '\n', "Test for normal distrinution and check for outliers or any representation of skewed data and constant variance of the errors")

```
**(Assess Normality)**
```{r, echo = FALSE}
library(EnvStats)
Prof.model = lm(Annual ~ Prof, data = SalaryData)
Region.model = lm(Annual ~ Region, data = SalaryData)

qqnorm(Prof.model$residuals)
qqline(Prof.model$residuals)
prof.e.i <- Prof.model$residuals
profSW.test <- shapiro.test(prof.e.i)
profSW.test
cat("SW p-val = 0.5585", '\n',"The qq line and the plots seem to represent an approximate normal distribution, as y is not equal to x for the above plot,and by Shapiro-Wilks test, the pval is fairly larger, and thus we accept the claim that the distribuition for Profession and Annual Salary is normally distribution")

qqnorm(Region.model$residuals)
qqline(Region.model$residuals)
reg.e.i <- Region.model$residuals
SW.test.reg <- shapiro.test(reg.e.i)
SW.test.reg
cat("SW p-val = 0.5231", '\n',"The qq line and the plots seem to represent an approximate normal distribution, as y is not equal to x for the above plot, and by Shapiro-Wilks test, the pval is fairly larger, and thus we accept the claim that the distribuition for Region and Annual Salary is normally distribution")

```
**(homoscedasticity)**
```{r, echo = FALSE}
cat('\n')

prof.residuals = rstandard(Prof.model)
library(ggplot2)
qplot(Prof, prof.residuals, data = Prof.model) + ggtitle("Errors vs. Groups") + xlab("Groups") + ylab("Errors") + geom_hline(yintercept = 0,col = "black")

reg.residuals = rstandard(Region.model)
qplot(Region, reg.residuals, data = Region.model) + ggtitle("Errors vs. Groups") + xlab("Groups") + ylab("Errors") + geom_hline(yintercept = 0,col = "black")

cat("The errors for the sampled population seem to have roughly the same variance.")


```


## Analysis
**(Interaction Effects)**
```{r, echo = FALSE}


cat("Assuming level of significance(alpha) as 0.05, test for interaction.", '\n')
alpha = 0.05

AB.model = lm(Annual ~ Prof*Region, data = SalaryData)
A.B.model = lm(Annual ~ Prof + Region, data = SalaryData)

SSE.AB <- sum(AB.model$residuals^2)
cat("(AB) : interaction model", SSE.AB, '\n')

SSE.A.B <- sum(A.B.model$residuals^2)
cat("(A+B): no-interaction model", SSE.A.B, '\n')

results.salaryAnova = anova(A.B.model,AB.model)
cat("test-statistic: ", results.salaryAnova[2,5], " p-value: ", results.salaryAnova[2,6], '\n', 
    "As the p-value is greater than the significance level, we fail to reject H0 and conclude that the model with no-interation effects is statistically better fit.", '\n', "As the no-interaction model is a better fit, we proceed testing for Factor A&B effects")

```
**(Factor Effects)**
```{r, echo = FALSE}


Partial.R2 = function(small.model,big.model){
  SSE1 = sum(small.model$residuals^2)
  SSE2 = sum(big.model$residuals^2)
  PR2 = (SSE1 - SSE2)/SSE1
  return(PR2)
}

resultsA = anova(Prof.model,A.B.model)
cat("test-statistic: ", resultsA[2,5], " p-value: ", resultsA[2,6], '\n', "As the p-value is less than alpha(0.05), we reject H0 and conclude that factor A effects exist", '\n', "R2{A+B|B}: ",Partial.R2(small.model = Region.model,big.model = A.B.model), '\n', "the propotion of reduction in error when adding factor A to B is 59.7%.")


resultsB = anova(Region.model,A.B.model)
cat("test-statistic: ", resultsB[2,5], " p-value: ", resultsB[2,6],'\n', "As the p-value is less than alpha(0.05), we reject H0 and conclude that factor B effects exist", '\n', "R2{A+B|A}: ",Partial.R2(small.model = Prof.model,big.model = A.B.model), '\n', "the propotion of reduction in error when adding factor B to A is 9.6%.")

```
**(No-Interaction Two Factor ANOVA)**
```{r, echo = FALSE}

cat("Yijk =  μ.. + γi + δj + εijk")

scary.CI = function(the.data,MSE,equal.weights = TRUE,multiplier,group,cs){
   if(sum(cs) != 0 & sum(cs !=0 ) != 1){
    return("Error - you did not input a valid contrast")
  }else{
    the.means = find.means(the.data)
    the.ns =find.means(the.data,length)
    nt = nrow(the.data)
    a = length(unique(the.data[,2]))
    b = length(unique(the.data[,3]))
    if(group =="A"){
      if(equal.weights == TRUE){
        a.means = rowMeans(the.means$AB)
        est = sum(a.means*cs)
        mul = rowSums(1/the.ns$AB)
        SE = sqrt(MSE/b^2 * (sum(cs^2*mul)))
        N = names(a.means)[cs!=0]
        CS = paste("(",cs[cs!=0],")",sep = "")
        fancy = paste(paste(CS,N,sep =""),collapse = "+")
        names(est) = fancy
      } else{
        a.means = the.means$A
        est = sum(a.means*cs)
        SE = sqrt(MSE*sum(cs^2*(1/the.ns$A)))
        N = names(a.means)[cs!=0]
        CS = paste("(",cs[cs!=0],")",sep = "")
        fancy = paste(paste(CS,N,sep =""),collapse = "+")
        names(est) = fancy
      }
    }else if(group == "B"){
      if(equal.weights == TRUE){
        b.means = colMeans(the.means$AB)
        est = sum(b.means*cs)
        mul = colSums(1/the.ns$AB)
        SE = sqrt(MSE/a^2 * (sum(cs^2*mul)))
        N = names(b.means)[cs!=0]
        CS = paste("(",cs[cs!=0],")",sep = "")
        fancy = paste(paste(CS,N,sep =""),collapse = "+")
        names(est) = fancy
      } else{
        b.means = the.means$B
        est = sum(b.means*cs)
        SE = sqrt(MSE*sum(cs^2*(1/the.ns$B)))
        N = names(b.means)[cs!=0]
        CS = paste("(",cs[cs!=0],")",sep = "")
        fancy = paste(paste(CS,N,sep =""),collapse = "+")
        names(est) = fancy
      }
    } else if(group == "AB"){
      est = sum(cs*the.means$AB)
      SE = sqrt(MSE*sum(cs^2/the.ns$AB))
      names(est) = "someAB"
    }
    the.CI = est + c(-1,1)*multiplier*SE
    results = c(est,the.CI)
    names(results) = c(names(est),"lower bound","upper bound")
    return(results)
  }
}

find.mult = function(alpha,a,b,dfSSE,g,group){
  if(group == "A"){
    Tuk = round(qtukey(1-alpha,a,dfSSE)/sqrt(2),3)
    Bon = round(qt(1-alpha/(2*g), dfSSE ) ,3)
    Sch = round(sqrt((a-1)*qf(1-alpha, a-1, dfSSE)),3) 
  }else if(group == "B"){
    Tuk = round(qtukey(1-alpha,b,dfSSE)/sqrt(2),3)
    Bon = round(qt(1-alpha/(2*g), dfSSE ) ,3)
    Sch = round(sqrt((b-1)*qf(1-alpha, b-1, dfSSE)),3) 
  }else if(group == "AB"){
    Tuk = round(qtukey(1-alpha,a*b,dfSSE)/sqrt(2),3)
    Bon = round(qt(1-alpha/(2*g), dfSSE ) ,3)
    Sch = round(sqrt((a*b-1)*qf(1-alpha, a*b-1, dfSSE)),3) 
  }
  results = c(Bon, Tuk,Sch)
  names(results) = c("Bonferroni","Tukey","Scheffe")
  return(results)
}

```
**(Confidence Intervals)**
```{r, echo = FALSE}

cat("Factor A (Profession) and Factor B (Region), pairwise comparisions.")
#salary.means
salary.NImodel = lm(Annual ~ Prof + Region, data = SalaryData)
SSE.NImodel = sum(salary.NImodel$residuals^2)
MSE.NImodel = SSE.NImodel/(ntSD-aSD-bSD+1)

#Pairwise comparison -1
SalaryA.cs = matrix(0,nrow = 2, ncol = 3)
SalaryA.cs[1,1] = 1
SalaryA.cs[2,1] = -1
all.mult.A = find.mult(alpha  = 0.05, a = aSD, b = bSD, dfSSE = ntSD-aSD-bSD+1, g = 1, group = "AB")
BonA <- all.mult.A[1]
SalaryA.CI <- scary.CI(SalaryData,MSE.NImodel,equal.weights = TRUE,BonA,"AB",SalaryA.cs)
cat("μ11 - μ12, difference in annual salary for Bioinformatics Engineer in Seattle and San Francisco", '\n', SalaryA.CI[2], SalaryA.CI[3],"are the bounds", '\n', "We are 95% confident that there exists no significant difference between a Bioinformatics Engineer in Seattle and San Francisco in terms of average annual salary because the confidence interval inculdes 0.", '\n')

#Pairwise comparison -2
SalaryB.cs = matrix(0,nrow = 2, ncol = 3)
SalaryB.cs[1,2] = 1
SalaryB.cs[2,2] = -1
all.mult.B = find.mult(alpha  = 0.05, a = aSD, b = bSD, dfSSE = ntSD-aSD-bSD+1, g = 1, group = "AB")
BonB <- all.mult.B[1]
SalaryB.CI <- scary.CI(SalaryData,MSE.NImodel,equal.weights = TRUE,BonA,"AB",SalaryB.cs)
cat("μ21 - μ22, difference in annual salary for Data Scientist in Seattle and San Francisco", '\n', SalaryB.CI[2], SalaryB.CI[3],"are the bounds", '\n', "We are 95% confident that there exists no significant difference between a Data Scientist in Seattle and San Francisco in terms of average annual salary because the confidence interval inculdes 0.", '\n')

#Pairwise comparison -3
SalaryC.cs = matrix(0,nrow = 2, ncol = 3)
SalaryC.cs[1,3] = 1
SalaryC.cs[2,3] = -1
all.mult.C = find.mult(alpha  = 0.05, a = aSD, b = bSD, dfSSE = ntSD-aSD-bSD+1, g = 1, group = "AB")
BonC <- all.mult.C[1]
SalaryC.CI <- scary.CI(SalaryData,MSE.NImodel,equal.weights = TRUE,BonA,"AB",SalaryC.cs)
cat("μ31 - μ32, difference in annual salary for Software Engineer in Seattle and San Francisco", '\n', SalaryC.CI[2], SalaryC.CI[3],"are the bounds", '\n', "We are 95% confident that there exists a significant difference between a Software Engineer from Seatlle and San Francisco in terms of annual salary, and the an average Software Engineer from San Francisco has a higher annual salary of 22.08602 to 7.344723 thousand dollars more.", '\n')

#Pairwise comparison -4
SalaryD.cs = c(1,-1)
all.mult.D = find.mult(alpha  = 0.05, a = aSD, b = bSD, dfSSE = ntSD-aSD-bSD+1, g = 1, group = "A")[2]
BonD <- all.mult.D
SalaryD.CI <- scary.CI(SalaryData,MSE.NImodel,equal.weights = TRUE,BonD,"A",SalaryD.cs)
cat("μ.1 - μ.2, difference in annual salary in Seattle and San Francisco", '\n', SalaryD.CI[2], SalaryD.CI[3],"are the bounds", '\n', "We are 95% confident that there exists no significant difference between on average in profession in Seattle and San Francisco in terms of average annual salary because the confidence interval inculdes 0.", '\n')

#Pairwise comparison -5
all.mult.E = find.mult(alpha  = 0.01, a = aSD, b = bSD, dfSSE = ntSD-aSD-bSD+1, g = 1, group = "AB")
SchE <- all.mult.E[3]
SalaryE.cs = matrix(0,nrow = 2, ncol = 3)
SalaryE.cs[1,1] = 1
SalaryE.cs[1,2] = -1/2
SalaryE.cs[1,3] = -1/2
SalaryE.CI <- scary.CI(SalaryData,MSE.NImodel,equal.weights = TRUE,SchE,"AB",SalaryE.cs)
cat("μ21 - (μ11+μ31)/2, difference in annual salary between a Data Scietist and the average of the engineers (Bioinformatics Engineer and Software) in Seattle", '\n', SalaryE.CI[2], SalaryE.CI[3])

#Pairwise comparison -6
all.mult.F = find.mult(alpha  = 0.01, a = aSD, b = bSD, dfSSE = ntSD-aSD-bSD+1, g = 1, group = "AB")
SchF <- all.mult.E[3]
SalaryF.cs = matrix(0,nrow = 2, ncol = 3)
SalaryF.cs[2,1] = 1
SalaryF.cs[2,2] = -1/2
SalaryF.cs[2,3] = -1/2
SalaryF.CI <- scary.CI(SalaryData,MSE.NImodel,equal.weights = TRUE,SchE,"AB",SalaryF.cs)
cat("μ22 - (μ12+μ32)/2, difference in annual salary between a Data Scietist and the average of the engineers (Bioinformatics Engineer and Software) in San Francisco", '\n', SalaryF.CI[2], SalaryF.CI[3])
```



## Interpretation
```{r, echo = FALSE}

cat("

Alpha(0.05), is the probability of rejecting the claim that there is an interaction effect between profession and city of residnece on sallary, when in reality there is. This is the probability of Type I error.

With our data set and question of interest, we completed a Two Factor Anova Hypothesis test. First we tested for interaction effects between profession and city of residence on sallary. With a pvalue of .0532 and greater than alpha, we concluded the model with no interaction effects is a statistically better fit. From there, we tested for Factor A and B effects. With both p-values, 0.0006384655 and 1.233952e-23, we concluded that both factor A and B effects exist. Therefore, the best model for this report is the No-Interaction Two Factor ANOVA. 

Through our confidence intervals, we have concluded that software engineers from San Francisco earn a average higher sallary than those from Seattle. Data Scientists have lower true average sallary than Bioinformatics engineer and Software engineers combined.  
")


```

## Conclusion
```{r, echo = FALSE}


cat("We can conclude that the best model for this report is the No-Interaction Two Factor ANOVA. We concluded that there is no interaction effect between Profession and City of residence on sallary. However, we concluded that there are individual factor A (Profession) and B (City) effects. ")
```

### R Appendix
```{r, ref.label=knitr::all_labels(),echo=FALSE,eval=FALSE}
```






